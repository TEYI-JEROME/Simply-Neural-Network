{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Reseau1 Class\n",
        "\n",
        "The `Reseau1` class is designed to implement a simple neural network with one hidden layer. This class enables the calculation of outputs based on input features using a feedforward approach.\n",
        "\n",
        "## Key Features\n",
        "\n",
        "- **Initialization**: The class is initialized with input data (`X`) and target outputs (`y`). It also sets up the weights for the connections between the input layer and the hidden layer, as well as between the hidden layer and the output layer.\n",
        "\n",
        "- **Forward Propagation**: The class includes methods to compute the weighted sum of inputs and apply the sigmoid activation function, which is a common choice for introducing non-linearity into the model.\n",
        "\n",
        "- **Output Calculation**: After processing through the hidden layer, the class computes the final outputs of the neural network, allowing for predictions based on the input data.\n",
        "\n"
      ],
      "metadata": {
        "id": "zZSOX1gBY65N"
      },
      "id": "zZSOX1gBY65N"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a500d6e",
      "metadata": {
        "id": "4a500d6e"
      },
      "outputs": [],
      "source": [
        "from math import exp\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\\\General Formula of the linear layer for the variable number $j: x^{\\prime}[j] = \\sum_j^m W[j][i] * X[j][i] + 30$  "
      ],
      "metadata": {
        "id": "sVUeD5ZCqQud"
      },
      "id": "sVUeD5ZCqQud"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that the bias is equal to 1. 4 neurones et 3 variables."
      ],
      "metadata": {
        "id": "N_Lv0AvPrAXh"
      },
      "id": "N_Lv0AvPrAXh"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X = [[1, 5, 6],\n",
        "      [3, 2, 1],\n",
        "      [0, 5, 11],\n",
        "      [3, 4, 1]]\n",
        "y = [0, 1, 0, 1]"
      ],
      "metadata": {
        "id": "6PJshGaOPIms"
      },
      "id": "6PJshGaOPIms",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "267e545a",
      "metadata": {
        "id": "267e545a"
      },
      "outputs": [],
      "source": [
        "class Reseau1:\n",
        "    \"\"\"This class allows us to calculate the output using\n",
        "    a neural network with one hidden layer. It initializes\n",
        "    the weights and provides methods for forward propagation\n",
        "    through the network.\n",
        "\n",
        "    Consider filling the ...... by the corresponding code\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, X, y):\n",
        "        \"\"\"Initializes the neural network with input features X and target outputs y.\n",
        "\n",
        "        Parameters:\n",
        "        X : list\n",
        "            A 2D list where each sublist represents a sample of input features.\n",
        "        y : list\n",
        "            A list of target outputs corresponding to each sample in X.\n",
        "\n",
        "        Attributes:\n",
        "        W1 : list\n",
        "            Weights for the connections from input layer to hidden layer.\n",
        "        W2 : list\n",
        "            Weights for the connections from hidden layer to output layer.\n",
        "        n_x : int\n",
        "            The number of input features (variables).\n",
        "        m : int\n",
        "            The number of samples (data points).\n",
        "        \"\"\"\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.W1 = [[4, 2, -1],\n",
        "                   [-1, 3, 2],\n",
        "                   [-1, -1, 3],\n",
        "                   [-1, -4, -2]]  # Weights for the hidden layer\n",
        "        self.W2 = [10, 4, -6, 3]  # Weights for the output layer\n",
        "\n",
        "        # Define n_x (the number of input features)\n",
        "        self.n_x = len(X[0])\n",
        "\n",
        "        # Define m (the number of samples)\n",
        "        self.m = len(X)\n",
        "\n",
        "    def Z(self):\n",
        "        \"\"\"Calculates the weighted sum of inputs plus bias for each neuron in the hidden layer.\n",
        "\n",
        "        Returns:\n",
        "        Z1 : list\n",
        "            A 2D list where each sublist contains the computed values for the\n",
        "            neurons in the hidden layer for each input sample.\n",
        "        \"\"\"\n",
        "        Z1 = []\n",
        "        for i in range(self.m):\n",
        "            # Initialize the sum for each neuron in the hidden layer\n",
        "            Z1_1 = 30\n",
        "            Z2_1 = 30\n",
        "            Z3_1 = 30\n",
        "            Z4_1 = 30\n",
        "            for j in range(self.n_x):\n",
        "                # Calculate the weighted sum for each neuron by multiplying inputs with weights\n",
        "                # The error was caused by trying to access self.W1[4], which is out of bounds\n",
        "                # because self.W1 only has elements at indices 0, 1, 2, and 3.\n",
        "                # The code below corrects this by accessing the elements using the correct indices.\n",
        "                Z1_1 += self.W1[0][j] * self.X[i][j]\n",
        "                Z2_1 += self.W1[1][j] * self.X[i][j]\n",
        "                Z3_1 += self.W1[2][j] * self.X[i][j]\n",
        "                Z4_1 += self.W1[3][j] * self.X[i][j]\n",
        "            Z1.append([Z1_1, Z2_1, Z3_1, Z4_1])  # Append results for the current sample\n",
        "        return Z1\n",
        "\n",
        "    def sigmoide(self, Z):\n",
        "        \"\"\"Implements the sigmoid activation function.\n",
        "\n",
        "        Parameters:\n",
        "        Z : float\n",
        "            The input value for which the sigmoid is calculated.\n",
        "\n",
        "        Returns:\n",
        "        float\n",
        "            The output of the sigmoid function.\n",
        "        \"\"\"\n",
        "        return  1/(1+exp(-Z))\n",
        "\n",
        "    def activation1(self):\n",
        "        \"\"\"Calculates the activation of the hidden layer using the sigmoid function.\n",
        "\n",
        "        Returns:\n",
        "        sigmos : list\n",
        "            A 2D list of activated values for each neuron in the hidden layer\n",
        "            for each input sample.\n",
        "        \"\"\"\n",
        "        Z = self.Z()  # Get the weighted sums\n",
        "        sigmos = []\n",
        "        for i in range(self.m):\n",
        "            sigmo = []\n",
        "            for j in range(4):\n",
        "                sigmo.append(self.sigmoide(Z[i,j]))  # Apply sigmoid to each neuron's input\n",
        "            sigmos.append(sigmo)  # Append activated values for the current sample\n",
        "        return sigmos\n",
        "\n",
        "    def activation2(self):\n",
        "        \"\"\"Calculates the final output of the neural network.\n",
        "\n",
        "        Returns:\n",
        "        sorties : list\n",
        "            A list of outputs from the output layer after applying the sigmoid function.\n",
        "        \"\"\"\n",
        "        activation1 = self.activation1()  # Get activations from the hidden layer\n",
        "        sorties = []\n",
        "        for i in range(4):\n",
        "            somme = 30  # Initialize the sum for the output layer\n",
        "            for j in range(4):\n",
        "                somme +=self.W2[j]*activation1[i][j] # Compute the weighted sum for the output\n",
        "            sorties.append(self.sigmoide(somme))  # Apply sigmoid to get the final output\n",
        "        return sorties"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vectorize the forward pass of the following class."
      ],
      "metadata": {
        "id": "b6qI1EUORGuY"
      },
      "id": "b6qI1EUORGuY"
    },
    {
      "cell_type": "code",
      "source": [
        "class Reseau2:\n",
        "    \"\"\"This class allows us to calculate the output using\n",
        "    a neural network with one hidden layer. It initializes\n",
        "    the weights and provides methods for forward propagation\n",
        "    through the network.\n",
        "\n",
        "    Consider filling the ...... by the corresponding code\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, X, y):\n",
        "        \"\"\"Initializes the neural network with input features X and target outputs y.\n",
        "\n",
        "        Parameters:\n",
        "        X : list\n",
        "            A 2D list where each sublist represents a sample of input features.\n",
        "        y : list\n",
        "            A list of target outputs corresponding to each sample in X.\n",
        "\n",
        "        Attributes:\n",
        "        W1 : list\n",
        "            Weights for the connections from input layer to hidden layer.\n",
        "        W2 : list\n",
        "            Weights for the connections from hidden layer to output layer.\n",
        "        n_x : int\n",
        "            The number of input features (variables).\n",
        "        m : int\n",
        "            The number of samples (data points).\n",
        "        \"\"\"\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.W1 = [[4, 2, -1],\n",
        "                   [-1, 3, 2],\n",
        "                   [-1, -1, 3],\n",
        "                   [-1, -4, -2]]  # Weights for the hidden layer\n",
        "        self.W2 = [10, 4, -6, 3]  # Weights for the output layer\n",
        "\n",
        "        # Define n_x (the number of input features)\n",
        "        self.n_x = len(X[0])\n",
        "\n",
        "        # Define m (the number of samples)\n",
        "        self.m = len(X)\n",
        "\n",
        "    def Z(self):\n",
        "        \"\"\"Calculates the weighted sum of inputs plus bias for each neuron in the hidden layer.\n",
        "\n",
        "        Returns:\n",
        "        Z1 : list\n",
        "            A 2D list where each sublist contains the computed values for the\n",
        "            neurons in the hidden layer for each input sample.\n",
        "        \"\"\"\n",
        "        Z1 = []\n",
        "        for i in range(self.m):\n",
        "            # Initialize the sum for each neuron in the hidden layer\n",
        "            Z1_1 = 30\n",
        "            Z2_1 = 30\n",
        "            Z3_1 = 30\n",
        "            Z4_1 = 30\n",
        "            for j in range(self.n_x):\n",
        "                # Calculate the weighted sum for each neuron by multiplying inputs with weights\n",
        "                # The error was caused by trying to access self.W1[4], which is out of bounds\n",
        "                # because self.W1 only has elements at indices 0, 1, 2, and 3.\n",
        "                # The code below corrects this by accessing the elements using the correct indices.\n",
        "                Z1_1 += self.W1[0][j] * self.X[i][j]\n",
        "                Z2_1 += self.W1[1][j] * self.X[i][j]\n",
        "                Z3_1 += self.W1[2][j] * self.X[i][j]\n",
        "                Z4_1 += self.W1[3][j] * self.X[i][j]\n",
        "            Z1.append([Z1_1, Z2_1, Z3_1, Z4_1])  # Append results for the current sample\n",
        "        return Z1\n",
        "\n",
        "    def sigmoide(self, Z):\n",
        "        \"\"\"Implements the sigmoid activation function.\n",
        "\n",
        "        Parameters:\n",
        "        Z : float\n",
        "            The input value for which the sigmoid is calculated.\n",
        "\n",
        "        Returns:\n",
        "        float\n",
        "            The output of the sigmoid function.\n",
        "        \"\"\"\n",
        "        return  1/(1+exp(-Z))\n",
        "\n",
        "    def activation1(self):\n",
        "        \"\"\"Calculates the activation of the hidden layer using the sigmoid function.\n",
        "\n",
        "        Returns:\n",
        "        sigmos : list\n",
        "            A 2D list of activated values for each neuron in the hidden layer\n",
        "            for each input sample.\n",
        "        \"\"\"\n",
        "        Z = self.Z()  # Get the weighted sums\n",
        "        sigmos = []\n",
        "        for i in range(self.m):\n",
        "            sigmo = []\n",
        "            for j in range(4):\n",
        "                sigmo.append(self.sigmoide(Z[i,j]))  # Apply sigmoid to each neuron's input\n",
        "            sigmos.append(sigmo)  # Append activated values for the current sample\n",
        "        return sigmos\n",
        "\n",
        "    def activation2(self):\n",
        "        \"\"\"Calculates the final output of the neural network.\n",
        "\n",
        "        Returns:\n",
        "        sorties : list\n",
        "            A list of outputs from the output layer after applying the sigmoid function.\n",
        "        \"\"\"\n",
        "        activation1 = self.activation1()  # Get activations from the hidden layer\n",
        "        sorties = []\n",
        "        for i in range(4):\n",
        "            somme = 30  # Initialize the sum for the output layer\n",
        "            for j in range(4):\n",
        "                somme +=self.W2[j]*activation1[i][j] # Compute the weighted sum for the output\n",
        "            sorties.append(self.sigmoide(somme))  # Apply sigmoid to get the final output\n",
        "        return sorties"
      ],
      "metadata": {
        "id": "c9mE32qCCcN9"
      },
      "id": "c9mE32qCCcN9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecbe0538",
      "metadata": {
        "id": "ecbe0538"
      },
      "outputs": [],
      "source": [
        "reseau1 = Reseau1(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14092488",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14092488",
        "outputId": "928dc8be-4f21-4d29-f044-04d33c085f87"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[38, 56, 42, -3], [45, 35, 28, 17], [29, 67, 58, -12], [49, 41, 26, 9]]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "reseau1.Z()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04d7a1d2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04d7a1d2",
        "outputId": "7343de9e-06dc-47be-ae20-e9ce1d608f91"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.9999999999999982,\n",
              "  0.9999999999997455,\n",
              "  0.9999999999997455,\n",
              "  0.9999999999997455],\n",
              " [0.9999999999999982,\n",
              "  0.9999999999999998,\n",
              "  0.9999999999993086,\n",
              "  0.9999999997210531],\n",
              " [0.9999999943972036, 1.0, 1.0, 0.9996646498695336],\n",
              " [1.0, 0.9999999999981204, 0.9999999999981204, 0.9999999999981204]]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "reseau1.activation1()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14b42c81",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14b42c81",
        "outputId": "baee4a61-ca31-41e6-a10e-c85ff9c16fd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We obtain the following outputs.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0, 1.0, 1.0, 1.0]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "print(\"We obtain the following outputs.\")\n",
        "reseau1.activation2()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}